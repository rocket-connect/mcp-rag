/* eslint-disable @typescript-eslint/no-var-requires */
import { writeFileSync, mkdirSync } from 'fs'
import { join } from 'path'
import type { BenchmarkConfig } from '../benchmark-config'
import type { BenchmarkSummary } from './markdown'

/**
 * Export benchmark summary to file for CI consumption
 */
export function saveBenchmarkResults(
  config: BenchmarkConfig,
  summary: BenchmarkSummary
): void {
  try {
    const resultsDir = join(process.cwd(), 'results', config.id)
    mkdirSync(resultsDir, { recursive: true })

    const summaryPath = join(resultsDir, 'benchmark-summary.json')
    writeFileSync(summaryPath, JSON.stringify(summary, null, 2))

    console.log(`\nâœ… Saved benchmark summary to ${summaryPath}`)

    // Generate markdown report
    const markdownReport = generateMarkdownReport(config, summary)
    const latestReportPath = join(resultsDir, 'latest.md')
    writeFileSync(latestReportPath, markdownReport)

    console.log(`âœ… Saved latest report to ${latestReportPath}`)

    // Save historical report
    const historyDir = join(resultsDir, 'history')
    mkdirSync(historyDir, { recursive: true })

    const timestamp = new Date()
      .toISOString()
      .replace(/T/, '-')
      .replace(/\..+/, '')
      .replace(/:/g, '-')
      .split('-')
      .slice(0, 3)
      .join('-')
    const historyPath = join(historyDir, `${timestamp}.md`)
    writeFileSync(historyPath, markdownReport)

    console.log(`âœ… Saved historical report to ${historyPath}`)
  } catch (error) {
    console.error('âŒ Failed to save benchmark results:', error)
  }
}

function generateMarkdownReport(
  config: BenchmarkConfig,
  summary: BenchmarkSummary
): string {
  const timestamp = new Date().toLocaleString('en-US', {
    month: '2-digit',
    day: '2-digit',
    year: 'numeric',
    hour: '2-digit',
    minute: '2-digit',
    second: '2-digit',
  })

  let markdown = `# ðŸš€ MCP-RAG Multi-Benchmark Report\n\n`
  markdown += `**Generated:** ${timestamp}\n\n`
  markdown += `## ðŸ“ Git Information\n\n`
  markdown += `- **Commit:** \`${getGitCommit()}\`\n`
  markdown += `- **Branch:** \`${getGitBranch()}\`\n\n`
  markdown += `## ðŸ“Š Overview\n\n`
  markdown += `**Total Benchmarks:** 1\n\n`
  markdown += `## ðŸŽ¯ ${config.name}\n\n`
  markdown += `> ${config.description}\n\n`
  markdown += `### ðŸ“Š Summary\n\n`
  markdown += `- **Total Tests:** ${summary.totalTests}\n`
  markdown += `- **Successful Tests:** ${summary.successfulTests} (${summary.toolCallSuccessRate.toFixed(1)}%)\n`
  markdown += `- **Failed Tests:** ${summary.failedTests}\n\n`
  markdown += `### âš¡ Performance\n\n`
  markdown += `- **Total Response Time:** ${summary.totalResponseTime}ms\n`
  markdown += `- **Average Response Time:** ${summary.averageResponseTime}ms\n`
  markdown += `- **Min Response Time:** ${summary.minResponseTime}ms\n`
  markdown += `- **Max Response Time:** ${summary.maxResponseTime}ms\n\n`
  markdown += `### ðŸ”¢ Token Usage\n\n`
  markdown += `- **Total Tokens:** ${summary.totalTokens.toLocaleString()}\n`
  markdown += `- **Prompt Tokens:** ${summary.totalPromptTokens.toLocaleString()}\n`
  markdown += `- **Completion Tokens:** ${summary.totalCompletionTokens.toLocaleString()}\n`
  markdown += `- **Average Tokens per Test:** ${summary.averageTokens.toLocaleString()}\n`
  markdown += `- **Min Tokens:** ${summary.minTokens.toLocaleString()}\n`
  markdown += `- **Max Tokens:** ${summary.maxTokens.toLocaleString()}\n\n`
  markdown += `### ðŸ“ˆ Detailed Metrics\n\n`
  markdown += `| #   | Tool Called       | Prompt Tokens | Completion Tokens | Total Tokens | Cumulative | Response Time | Messages |\n`
  markdown += `| --- | ----------------- | ------------- | ----------------- | ------------ | ---------- | ------------- | -------- |\n`

  summary.metrics.forEach(m => {
    const toolName = m.selectedTool || 'None'
    markdown += `| ${m.prompt}   | ${toolName.padEnd(17)} | ${m.promptTokens.toLocaleString().padStart(13)} | ${m.completionTokens.toLocaleString().padStart(17)} | ${m.tokenCount.toLocaleString().padStart(12)} | ${m.cumulativeTokens.toLocaleString().padStart(10)} | ${m.responseTime.toLocaleString().padStart(13)} ms | ${String(m.conversationLength).padStart(8)} |\n`
  })

  markdown += `\n### ðŸ”§ Tool Usage\n\n`
  markdown += `| Tool              | Count |\n`
  markdown += `| ----------------- | ----- |\n`

  const toolCounts: Record<string, number> = {}
  summary.metrics.forEach(m => {
    if (m.toolCalled) {
      toolCounts[m.toolCalled] = (toolCounts[m.toolCalled] || 0) + 1
    }
  })

  Object.entries(toolCounts)
    .sort((a, b) => b[1] - a[1])
    .forEach(([tool, count]) => {
      markdown += `| ${tool.padEnd(17)} | ${count}     |\n`
    })

  markdown += `\n---\n\n`
  markdown += `_Generated by MCP-RAG Benchmark Suite_\n`

  return markdown
}

function getGitCommit(): string {
  try {
    const { execSync } = require('child_process')
    return execSync('git rev-parse --short HEAD').toString().trim()
  } catch {
    return 'unknown'
  }
}

function getGitBranch(): string {
  try {
    const { execSync } = require('child_process')
    return execSync('git rev-parse --abbrev-ref HEAD').toString().trim()
  } catch {
    return 'unknown'
  }
}
